{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural & Behavioral Modeling - Week 12 (Exercises)\n",
    "趙冠豪 (ntueeb05howard@gmail.com)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solving environment: failed\n",
      "\n",
      "PackagesNotFoundError: The following packages are not available from current channels:\n",
      "\n",
      "  - torchvision-cpu\n",
      "  - pytorch-cpu\n",
      "\n",
      "Current channels:\n",
      "\n",
      "  - https://conda.anaconda.org/pytorch/osx-64\n",
      "  - https://conda.anaconda.org/pytorch/noarch\n",
      "  - https://repo.anaconda.com/pkgs/main/osx-64\n",
      "  - https://repo.anaconda.com/pkgs/main/noarch\n",
      "  - https://repo.anaconda.com/pkgs/free/osx-64\n",
      "  - https://repo.anaconda.com/pkgs/free/noarch\n",
      "  - https://repo.anaconda.com/pkgs/r/osx-64\n",
      "  - https://repo.anaconda.com/pkgs/r/noarch\n",
      "  - https://repo.anaconda.com/pkgs/pro/osx-64\n",
      "  - https://repo.anaconda.com/pkgs/pro/noarch\n",
      "\n",
      "To search for alternate channels that may provide the conda package you're\n",
      "looking for, navigate to\n",
      "\n",
      "    https://anaconda.org\n",
      "\n",
      "and use the search bar at the top of the page.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Upgrade PyTorch to 0.4.0 if necessary:\n",
    "! conda install -y pytorch-cpu torchvision-cpu -c pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config IPCompleter.greedy=True \n",
    "%matplotlib inline\n",
    "from matplotlib.pyplot import *\n",
    "from IPython.display import *\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 0.4.0\n",
      "No GPU\n"
     ]
    }
   ],
   "source": [
    "# Check GPU status:\n",
    "import torch as t\n",
    "print('PyTorch version:',t.__version__)\n",
    "use_cuda=t.cuda.is_available()\n",
    "if(use_cuda):\n",
    "    for i in range(t.cuda.device_count()):\n",
    "        print('Device ',i,':',t.cuda.get_device_name(i))\n",
    "    print('Current: Device ',t.cuda.current_device())\n",
    "    t.backends.cudnn.benchmark = True \n",
    "    device = t.device(\"cuda\")\n",
    "else:\n",
    "    t.manual_seed(999)\n",
    "    device = t.device(\"cpu\")\n",
    "    print('No GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Fair Performance Evaluation (5 points)\n",
    "We often compare and assess performances of different model architectures/parameters/hyperparameters. Note that the results are differnt even if you re-run exactly the same code block. This is primarily due to a non-fixed random number seed. Please:\n",
    "\n",
    "(1) run the section 1.2 TEN times and report (a) min, (b) max, (c) mean, & (d) standard deviation of the TESTING accuracies. (3 points)\n",
    "\n",
    "(2) try to fix the random number seeds in numpy & pytorch to see if you can obtain the same results every time in the section 1.2. (2 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.0 CIFAR-10 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset:\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import CIFAR10\n",
    "train_set = CIFAR10(root='.', train=True, transform=transforms.ToTensor(),download=True)\n",
    "train_data = t.utils.data.DataLoader(train_set, batch_size=32, shuffle=True)\n",
    "test_set = CIFAR10(root='.', train=False, transform=transforms.ToTensor())\n",
    "test_data = t.utils.data.DataLoader(test_set, batch_size=1000, shuffle=True)\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x116450320>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 The model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the model:\n",
    "import torch as th\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__() # = nn.Module.__init__(self)\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5) # in, out, kernel\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5) \n",
    "        self.fc1   = nn.Linear(16*5*5, 120) \n",
    "        self.fc2   = nn.Linear(120, 84)\n",
    "        self.fc3   = nn.Linear(84, 10)\n",
    "    def forward(self, x): # functional expressions\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2) \n",
    "        x = x.view(x.size()[0], -1) \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenet = Net()\n",
    "lenet = lenet.to(device)\n",
    "loss_fn = t.nn.CrossEntropyLoss()\n",
    "optimizer = t.optim.Adam(lenet.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Training & Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "14\n",
      "19\n",
      "14\n",
      "23\n",
      "20\n",
      "19\n",
      "20\n",
      "16\n",
      "14\n",
      "19\n",
      "18\n",
      "22\n",
      "18\n",
      "21\n",
      "15\n",
      "16\n",
      "19\n",
      "19\n",
      "19\n",
      "16\n",
      "23\n",
      "18\n",
      "18\n",
      "19\n",
      "19\n",
      "15\n",
      "19\n",
      "21\n",
      "18\n",
      "17\n",
      "19\n",
      "16\n",
      "21\n",
      "17\n",
      "16\n",
      "21\n",
      "18\n",
      "13\n",
      "19\n",
      "17\n",
      "14\n",
      "19\n",
      "18\n",
      "14\n",
      "17\n",
      "20\n",
      "15\n",
      "17\n",
      "14\n",
      "20\n",
      "17\n",
      "16\n",
      "14\n",
      "15\n",
      "14\n",
      "16\n",
      "20\n",
      "15\n",
      "22\n",
      "16\n",
      "10\n",
      "12\n",
      "21\n",
      "17\n",
      "19\n",
      "20\n",
      "13\n",
      "23\n",
      "17\n",
      "20\n",
      "23\n",
      "15\n",
      "20\n",
      "24\n",
      "20\n",
      "16\n",
      "15\n",
      "18\n",
      "15\n",
      "21\n",
      "14\n",
      "19\n",
      "21\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-80ff24a448e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Training:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#         print(\"X_train : \", X_train, \"\\nY_train : \", Y_train)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    262\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    262\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torchvision-0.2.1-py3.6.egg/torchvision/datasets/cifar.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;31m# doing this so that it is consistent with all other datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;31m# to return a PIL Image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mfromarray\u001b[0;34m(obj, mode)\u001b[0m\n\u001b[1;32m   2374\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstrides\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2375\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'tobytes'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2376\u001b[0;31m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2377\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2378\u001b[0m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtostring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training:\n",
    "for e in range(2):\n",
    "    for i, (X_train, Y_train) in enumerate(train_data, 0):\n",
    "        X_train,Y_train=X_train.to(device),Y_train.to(device)\n",
    "#         print(\"X_train : \", X_train, \"\\nY_train : \", Y_train)\n",
    "        Y_pred = lenet(X_train)\n",
    "#         print(Y_pred)\n",
    "        loss = loss_fn(Y_pred, Y_train)\n",
    "        lenet.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()   \n",
    "        Y_pred = lenet(X_train)\n",
    "        Y_pred = t.max(Y_pred,1)[1]\n",
    "        print((Y_pred==Y_train).sum().item())\n",
    "    print('epoch ',e,':',(Y_pred==Y_train).sum().item()/Y_train.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test : 0.48\n"
     ]
    }
   ],
   "source": [
    "# Testing on a batch:\n",
    "dataiter = iter(test_data)\n",
    "X_test, Y_test = dataiter.next() # returning a batch\n",
    "X_test,Y_test=X_test.to(device),Y_test.to(device)\n",
    "with t.no_grad():\n",
    "    Y_pred = lenet(X_test)\n",
    "    Y_pred = t.max(Y_pred,1)[1]\n",
    "    print('test :',(Y_pred==Y_test).sum().item()/Y_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Your answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 answer  (report (a) min, (b) max, (c) mean, & (d) standard deviation of the TESTING accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.\n",
    "\n",
    "epoch  0 : 0.5\n",
    "epoch  1 : 0.1875\n",
    "test : 0.503\n",
    "\n",
    "2.\n",
    "\n",
    "epoch  0 : 0.5625\n",
    "epoch  1 : 0.4375\n",
    "test : 0.59\n",
    "\n",
    "3.\n",
    "\n",
    "epoch  0 : 0.8125\n",
    "epoch  1 : 0.5625\n",
    "test : 0.597\n",
    "\n",
    "4.\n",
    "\n",
    "epoch  0 : 0.75\n",
    "epoch  1 : 0.625\n",
    "test : 0.648\n",
    "\n",
    "5.\n",
    "\n",
    "epoch  0 : 0.5625\n",
    "epoch  1 : 0.6875\n",
    "test : 0.724\n",
    "\n",
    "6.\n",
    "\n",
    "epoch  0 : 0.75\n",
    "epoch  1 : 0.6875\n",
    "test : 0.693\n",
    "\n",
    "7.\n",
    "\n",
    "epoch  0 : 0.5\n",
    "epoch  1 : 0.375\n",
    "test : 0.509\n",
    "\n",
    "8.\n",
    "\n",
    "epoch  0 : 0.4375\n",
    "epoch  1 : 0.5625\n",
    "test : 0.516\n",
    "\n",
    "9.\n",
    "\n",
    "epoch  0 : 0.5625\n",
    "epoch  1 : 0.5625\n",
    "test : 0.591\n",
    "\n",
    "10.\n",
    "\n",
    "epoch  0 : 0.625\n",
    "epoch  1 : 0.75\n",
    "test : 0.599\n",
    "\n",
    "11.\n",
    "\n",
    "epoch  0 : 0.3125\n",
    "epoch  1 : 0.625\n",
    "test : 0.488\n",
    "\n",
    "12.\n",
    "\n",
    "epoch  0 : 0.5\n",
    "epoch  1 : 0.6875\n",
    "test : 0.618"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracy = [0.503, 0.59, 0.597, 0.648, 0.724, 0.693, 0.509, 0.516, 0.591, 0.599, 0.488, 0.618]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.488"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.724"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5896666666666667"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statistics as s\n",
    "s.mean(test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07559020298873913"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.stdev(test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**minimum : 0.488**\n",
    "\n",
    "**maximum : 0.724** \n",
    "\n",
    "**average : 0.590**\n",
    "\n",
    "**standard deviation : 0.076**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 answer ( fix the random number seeds)¶"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After setting seed() for cpu (```t.manual_seed(999)```)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. \n",
    "\n",
    "epoch  0 : 0.375\n",
    "epoch  1 : 0.5\n",
    "test : 0.48\n",
    "\n",
    "2.\n",
    "\n",
    "epoch  0 : 0.375\n",
    "epoch  1 : 0.5\n",
    "test : 0.48\n",
    "\n",
    "==> the same !!\n",
    "\n",
    "key point :\n",
    "\n",
    "Because I am using cpu, the way I fix the seed is to add `t.manual_seed(999)` when checking CPU state\n",
    "\n",
    "```\n",
    "# Check GPU status:\n",
    "import torch as t\n",
    "print('PyTorch version:',t.__version__)\n",
    "use_cuda=t.cuda.is_available()\n",
    "if(use_cuda):\n",
    "    for i in range(t.cuda.device_count()):\n",
    "        print('Device ',i,':',t.cuda.get_device_name(i))\n",
    "    print('Current: Device ',t.cuda.current_device())\n",
    "    t.backends.cudnn.benchmark = True \n",
    "    device = t.device(\"cuda\")\n",
    "else:\n",
    "    t.manual_seed(999)    # add this line to fix the seed\n",
    "    device = t.device(\"cpu\")\n",
    "    print('No GPU')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Self note"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LeNet()  : 較早期的神經網路  [關於辨認數字的model說明](http://noahsnail.com/2017/03/02/2017-3-2-LeNet神经网络/#2-1-LeNet第一层（卷积运算）)\n",
    "\n",
    "AlexNet()  : AlexNet包含8層變換，其中有五層卷積和兩層全連接隱含層，以及一個輸出層\n",
    "\n",
    "VGGNet()  : VGG使用了編程語言自帶的便利，採用了函數和循環的方式，複製了網絡結構裏面的大量重複結構，因此可以很緊湊來構造這些網絡。而第一個使用這種結構的深度網絡是VGG\n",
    "\n",
    "NiNNet()  : 一塊主要由卷積層構成，另一塊主要是全連接層。在Alexnet裏我們看到如何把卷積層塊和全連接層分別加深加寬從而得到深度網絡。另外一個自然的想法是，我們可以串聯數個卷積層塊和全連接層塊來構建深度網絡"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Universal Approximation Theorem (5 points)\n",
    "\n",
    "Please FAIRLY evaluate whether a deep network learns XOR more efficiently than a shallow network with the same number of model parameters. Please discuss why in either case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.0 XOR data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "N=1000 # samples per cluster\n",
    "XY=t.tensor([[5,5],[5,10],[10,5],[10,10]],dtype=t.float32) # 4 cluster centers\n",
    "Z=t.tensor([0,1,1,0]) # category labels\n",
    "t.cat([t.randn(2,1)+XY[0,0],t.randn(2,1)+XY[0,1]],1)\n",
    "xy,z=t.zeros(4*N,2),t.zeros(4*N,dtype=t.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 6.5122,  3.8789],\n",
       "        [ 4.8868,  5.2139]])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.cat([t.randn(2,1)+XY[0,0],t.randn(2,1)+XY[0,1]],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(xy[2*1000:(2+1)*1000,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1163046a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "N=1000 # samples per cluster\n",
    "XY=t.tensor([[5,5],[5,10],[10,5],[10,10]],dtype=t.float32) # 4 cluster centers\n",
    "Z=t.tensor([0,1,1,0]) # category labels\n",
    "t.cat([t.randn(2,1)+XY[0,0],t.randn(2,1)+XY[0,1]],1)\n",
    "xy,z=t.zeros(4*N,2),t.zeros(4*N,dtype=t.int64)\n",
    "for i in range(4):\n",
    "    xy[i*N:(i+1)*N,]=t.rand(N,2)+XY[i,]\n",
    "    z[i*N:(i+1)*N]=Z[i]\n",
    "xy_np=xy.numpy()\n",
    "z_np=z.numpy().astype(int)\n",
    "cmap=np.array([[1,0,0],[0,1,0]])\n",
    "scatter(xy_np[:,0],xy_np[:,1],color=cmap[z_np]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 A shallow net with one hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  0 : 0.4995\n",
      "epoch  1 : 0.56425\n",
      "epoch  2 : 0.63925\n",
      "epoch  3 : 0.684\n",
      "epoch  4 : 0.7135\n",
      "epoch  5 : 0.738\n",
      "epoch  6 : 0.74825\n",
      "epoch  7 : 0.75\n",
      "epoch  8 : 0.75\n",
      "epoch  9 : 0.75\n",
      "epoch  10 : 0.75\n",
      "epoch  11 : 0.75\n",
      "epoch  12 : 0.75\n",
      "epoch  13 : 0.75\n",
      "epoch  14 : 0.75\n",
      "epoch  15 : 0.75\n",
      "epoch  16 : 0.75\n",
      "epoch  17 : 0.75\n",
      "epoch  18 : 0.75\n",
      "epoch  19 : 0.75\n",
      "epoch  20 : 0.75\n",
      "epoch  21 : 0.75\n",
      "epoch  22 : 0.75\n",
      "epoch  23 : 0.76725\n",
      "epoch  24 : 0.8285\n",
      "epoch  25 : 0.90375\n",
      "epoch  26 : 0.946\n",
      "epoch  27 : 0.9805\n",
      "epoch  28 : 0.9975\n",
      "epoch  29 : 1.0\n",
      "epoch  30 : 1.0\n",
      "epoch  31 : 1.0\n",
      "epoch  32 : 1.0\n",
      "epoch  33 : 1.0\n",
      "epoch  34 : 1.0\n",
      "epoch  35 : 1.0\n",
      "epoch  36 : 1.0\n",
      "epoch  37 : 1.0\n",
      "epoch  38 : 1.0\n",
      "epoch  39 : 1.0\n",
      "epoch  40 : 1.0\n",
      "epoch  41 : 1.0\n",
      "epoch  42 : 1.0\n",
      "epoch  43 : 1.0\n",
      "epoch  44 : 1.0\n",
      "epoch  45 : 1.0\n",
      "epoch  46 : 1.0\n",
      "epoch  47 : 1.0\n",
      "epoch  48 : 1.0\n",
      "epoch  49 : 1.0\n",
      "epoch  50 : 1.0\n",
      "epoch  51 : 1.0\n",
      "epoch  52 : 1.0\n",
      "epoch  53 : 1.0\n",
      "epoch  54 : 1.0\n",
      "epoch  55 : 1.0\n",
      "epoch  56 : 1.0\n",
      "epoch  57 : 1.0\n",
      "epoch  58 : 1.0\n",
      "epoch  59 : 1.0\n",
      "epoch  60 : 1.0\n",
      "epoch  61 : 1.0\n",
      "epoch  62 : 1.0\n",
      "epoch  63 : 1.0\n",
      "epoch  64 : 1.0\n",
      "epoch  65 : 1.0\n",
      "epoch  66 : 1.0\n",
      "epoch  67 : 1.0\n",
      "epoch  68 : 1.0\n",
      "epoch  69 : 1.0\n",
      "epoch  70 : 1.0\n",
      "epoch  71 : 1.0\n",
      "epoch  72 : 1.0\n",
      "epoch  73 : 1.0\n",
      "epoch  74 : 1.0\n",
      "epoch  75 : 1.0\n",
      "epoch  76 : 1.0\n",
      "epoch  77 : 1.0\n",
      "epoch  78 : 1.0\n",
      "epoch  79 : 1.0\n",
      "epoch  80 : 1.0\n",
      "epoch  81 : 1.0\n",
      "epoch  82 : 1.0\n",
      "epoch  83 : 1.0\n",
      "epoch  84 : 1.0\n",
      "epoch  85 : 1.0\n",
      "epoch  86 : 1.0\n",
      "epoch  87 : 1.0\n",
      "epoch  88 : 1.0\n",
      "epoch  89 : 1.0\n",
      "epoch  90 : 1.0\n",
      "epoch  91 : 1.0\n",
      "epoch  92 : 1.0\n",
      "epoch  93 : 1.0\n",
      "epoch  94 : 1.0\n",
      "epoch  95 : 1.0\n",
      "epoch  96 : 1.0\n",
      "epoch  97 : 1.0\n",
      "epoch  98 : 1.0\n",
      "epoch  99 : 1.0\n"
     ]
    }
   ],
   "source": [
    "# Number of free parameters: 2*H+H*2=70\n",
    "\n",
    "H=35 # number of hidden units\n",
    "model = t.nn.Sequential(\n",
    "    t.nn.Linear(2, H, bias=False),\n",
    "    t.nn.BatchNorm1d(H),\n",
    "    t.nn.ReLU(),\n",
    "    t.nn.Linear(H, 2, bias=False),\n",
    "    t.nn.Softmax(dim=1)\n",
    ")\n",
    "loss_fn = t.nn.CrossEntropyLoss()\n",
    "optimizer = t.optim.Adam(model.parameters())\n",
    "\n",
    "for i in range(100):\n",
    "    z_pred = model(xy)\n",
    "    loss = loss_fn(z_pred,z)\n",
    "    model.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    z_pred = model(xy) \n",
    "    z_pred = t.max(z_pred,1)[1]\n",
    "    print('epoch ',i,':',(z_pred==z).sum().item()/xy.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 A \"deep\" net with three hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  0 : 0.5\n",
      "epoch  1 : 0.5\n",
      "epoch  2 : 0.5\n",
      "epoch  3 : 0.5\n",
      "epoch  4 : 0.5\n",
      "epoch  5 : 0.5\n",
      "epoch  6 : 0.5\n",
      "epoch  7 : 0.5\n",
      "epoch  8 : 0.5\n",
      "epoch  9 : 0.5\n",
      "epoch  10 : 0.5\n",
      "epoch  11 : 0.5\n",
      "epoch  12 : 0.5\n",
      "epoch  13 : 0.503\n",
      "epoch  14 : 0.5125\n",
      "epoch  15 : 0.5315\n",
      "epoch  16 : 0.55125\n",
      "epoch  17 : 0.57325\n",
      "epoch  18 : 0.60125\n",
      "epoch  19 : 0.62475\n",
      "epoch  20 : 0.647\n",
      "epoch  21 : 0.66875\n",
      "epoch  22 : 0.68775\n",
      "epoch  23 : 0.70625\n",
      "epoch  24 : 0.71875\n",
      "epoch  25 : 0.72725\n",
      "epoch  26 : 0.7345\n",
      "epoch  27 : 0.73925\n",
      "epoch  28 : 0.743\n",
      "epoch  29 : 0.74725\n",
      "epoch  30 : 0.74775\n",
      "epoch  31 : 0.7495\n",
      "epoch  32 : 0.75\n",
      "epoch  33 : 0.75\n",
      "epoch  34 : 0.75\n",
      "epoch  35 : 0.75\n",
      "epoch  36 : 0.75\n",
      "epoch  37 : 0.75\n",
      "epoch  38 : 0.75\n",
      "epoch  39 : 0.75\n",
      "epoch  40 : 0.75125\n",
      "epoch  41 : 0.759\n",
      "epoch  42 : 0.77275\n",
      "epoch  43 : 0.78775\n",
      "epoch  44 : 0.8065\n",
      "epoch  45 : 0.822\n",
      "epoch  46 : 0.836\n",
      "epoch  47 : 0.85275\n",
      "epoch  48 : 0.86925\n",
      "epoch  49 : 0.885\n",
      "epoch  50 : 0.89575\n",
      "epoch  51 : 0.9055\n",
      "epoch  52 : 0.9175\n",
      "epoch  53 : 0.9295\n",
      "epoch  54 : 0.9385\n",
      "epoch  55 : 0.94625\n",
      "epoch  56 : 0.95275\n",
      "epoch  57 : 0.9575\n",
      "epoch  58 : 0.96525\n",
      "epoch  59 : 0.96925\n",
      "epoch  60 : 0.974\n",
      "epoch  61 : 0.977\n",
      "epoch  62 : 0.97825\n",
      "epoch  63 : 0.979\n",
      "epoch  64 : 0.98\n",
      "epoch  65 : 0.98\n",
      "epoch  66 : 0.98025\n",
      "epoch  67 : 0.9805\n",
      "epoch  68 : 0.982\n",
      "epoch  69 : 0.98275\n",
      "epoch  70 : 0.9835\n",
      "epoch  71 : 0.9845\n",
      "epoch  72 : 0.98625\n",
      "epoch  73 : 0.9875\n",
      "epoch  74 : 0.98775\n",
      "epoch  75 : 0.98925\n",
      "epoch  76 : 0.99025\n",
      "epoch  77 : 0.991\n",
      "epoch  78 : 0.99225\n",
      "epoch  79 : 0.99275\n",
      "epoch  80 : 0.99325\n",
      "epoch  81 : 0.9945\n",
      "epoch  82 : 0.9955\n",
      "epoch  83 : 0.99625\n",
      "epoch  84 : 0.9965\n",
      "epoch  85 : 0.997\n",
      "epoch  86 : 0.9975\n",
      "epoch  87 : 0.9975\n",
      "epoch  88 : 0.99825\n",
      "epoch  89 : 0.99875\n",
      "epoch  90 : 0.999\n",
      "epoch  91 : 0.999\n",
      "epoch  92 : 0.99975\n",
      "epoch  93 : 0.99975\n",
      "epoch  94 : 1.0\n",
      "epoch  95 : 1.0\n",
      "epoch  96 : 1.0\n",
      "epoch  97 : 1.0\n",
      "epoch  98 : 1.0\n",
      "epoch  99 : 1.0\n"
     ]
    }
   ],
   "source": [
    "# Number of free parameters: 2*H+H*H+H*H+H*2=70\n",
    "\n",
    "H=5 # number of hidden units\n",
    "model = t.nn.Sequential(\n",
    "    t.nn.Linear(2, H, bias=False),\n",
    "    t.nn.BatchNorm1d(H),\n",
    "    t.nn.ReLU(),\n",
    "    t.nn.Linear(H, H,bias=False),\n",
    "    t.nn.BatchNorm1d(H),\n",
    "    t.nn.ReLU(),\n",
    "    t.nn.Linear(H, H, bias=False),\n",
    "    t.nn.BatchNorm1d(H),\n",
    "    t.nn.ReLU(),\n",
    "    t.nn.Linear(H, 2, bias=False),\n",
    "    t.nn.Softmax(dim=1)\n",
    ")\n",
    "loss_fn = t.nn.CrossEntropyLoss()\n",
    "optimizer = t.optim.Adam(model.parameters())\n",
    "\n",
    "for i in range(100):\n",
    "    z_pred = model(xy)\n",
    "    loss = loss_fn(z_pred,z)\n",
    "    model.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    z_pred = model(xy) \n",
    "    z_pred = t.max(z_pred,1)[1]\n",
    "    print('epoch ',i,':',(z_pred==z).sum().item()/xy.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Your answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please respond to the questions here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "從多次整體表現來看，shallow net 的表現的比 deep net 好，跟我原本預期的 deep net 會比較好有落差。推測是在這個case shallow 表現的比較好。我有觀察到deep net work 他會卡在某個值蠻久的，然後訓練的準確率才又提升。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "有觀察到的現象：\n",
    "1. 加入 bias term 表現的比沒有 bias term 好。\n",
    "2. adam 表現的比 SGD 好\n",
    "3. 如果把 deep net 的 learning rate 改成0.01 ，結果會比較好。\n",
    "4. 如果把 deep net 的 activation function 全部都改成 sigmod function，那麼結果會都變成0.5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
