{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural & Behavioral Modeling - Week 10 (Exercises)\n",
    "Howard Chao (ntueeb05howard@gmail.com)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config IPCompleter.greedy=True \n",
    "%matplotlib inline\n",
    "from numpy import *\n",
    "from matplotlib.pyplot import *\n",
    "from IPython.display import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 A Two-layered Linear Network as a Regression Model (7 points)\n",
    "Data fitting of the following network is poor. Please check if adding bias terms or chaging network hyperparameters (e.g., learning rate, amount of training, etc.) help. If not, please explain why the fitting is poor given that the network/regression model has sufficient degrees of freedom (i.e., network weights or regression coefficients) to overfit such a small data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_printoptions(precision=3,suppress=True)\n",
    "X=array([[1,0,0,0],[0,1,0,0],[1,1,0,0],[0,0,1,0],[0,0,0,1],[0,0,1,1]])\n",
    "Y=array([[1,0],[1,0],[1,0],[0,1],[0,1],[0,1]])\n",
    "[Np,Nx]=X.shape; # find numbers of patterns and input dimensions\n",
    "[Np,Ny]=Y.shape; # find numbers of patterns and output dimensions\n",
    "W=random.rand(Ny,Nx); # set initially random connectivity matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 0],\n",
       "       [0, 1, 0, 0],\n",
       "       [1, 1, 0, 0],\n",
       "       [0, 0, 1, 0],\n",
       "       [0, 0, 0, 1],\n",
       "       [0, 0, 1, 1]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.677,  0.203,  0.944,  0.559],\n",
       "       [ 0.626,  0.285,  0.128,  0.604]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Origin W: \n",
      " [[ 0.527  0.003  0.438  0.744]\n",
      " [ 0.914  0.063  0.83   0.629]]\n",
      "Ideal results:\n",
      "[[1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]]\n",
      "Reality:\n",
      "[[ 0.679  0.   ]\n",
      " [ 0.643 -0.   ]\n",
      " [ 1.321  0.   ]\n",
      " [-0.     0.643]\n",
      " [ 0.     0.643]\n",
      " [ 0.     1.286]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11391cda0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Here we train a two-layered network of units \n",
    "# with a linear activation function f(x)=x\n",
    "# to associate patterns using the delta rule dW=(t-y)*x\n",
    "\n",
    "set_printoptions(precision=3,suppress=True)\n",
    "\n",
    "X=array([[1,0,0,0],[0,1,0,0],[1,1,0,0],[0,0,1,0],[0,0,0,1],[0,0,1,1]])\n",
    "Y=array([[1,0],[1,0],[1,0],[0,1],[0,1],[0,1]])\n",
    "[Np,Nx]=X.shape; # find numbers of patterns and input dimensions\n",
    "[Np,Ny]=Y.shape; # find numbers of patterns and output dimensions\n",
    "W=random.rand(Ny,Nx); # set initially random connectivity matrix\n",
    "\n",
    "eta=.1; # set the learning rate \n",
    "tol=1e-2; # set the tolerance/stopping criterion; try 0.01\n",
    "nIts=50000; # set the maximum number of allowed iterations\n",
    "totErr=10; # set the maximum training error to an initially high value\n",
    "totErr_hist=[] # history of totall error\n",
    "\n",
    "print(\"Origin W: \\n\", W)\n",
    "\n",
    "for c in range(nIts): # for each learning iteration\n",
    "    p=mod(c,Np) # sequential presentation of the training samples (0 ~ 5)\n",
    "#     p=random.randint(nP); # choose a traing pattern at random\n",
    "    \n",
    "    # Forward propagation:\n",
    "    y=W.dot(X[p])\n",
    "#     print(\"y: \", y)\n",
    "    \n",
    "    # Backward propagation:\n",
    "    deltaW=eta*outer(Y[p].T-y,X[p]) # delta learning\n",
    "#     print(outer(Y[p].T-y,X[p]))\n",
    "    W=W+deltaW;  # apply the weight update\n",
    "#     print(c)\n",
    "#     print(W)\n",
    "    \n",
    "    # Checking if done:\n",
    "    if(mod(c,10*Np)==0): # after 10 updates check total errors (0, 60 ,120 ...)\n",
    "        predY=W.dot(X.T) # testing ALL the training samples (X transform 4*6)\n",
    "#         print(\"W : \\n\", W)\n",
    "#         print(\"X : \\n\", X.T)\n",
    "#         print(\"predY:\")\n",
    "#         print(\"Normal: \")\n",
    "#         print((Y.T-predY))\n",
    "#         print(\"Square: \")\n",
    "#         print((Y.T-predY)**2)\n",
    "#         print(predY.T) # predicted Y\n",
    "        totErr=sum((Y.T-predY)**2) # sum of squared errors for all samples\n",
    "        totErr_hist.append(totErr)\n",
    "#         print(\"totErr: \", totErr)\n",
    "    if(totErr<tol):\n",
    "        break # break if max error is below tolerance\n",
    "# print(\"len\", len(totErr_hist))\n",
    "plot(totErr_hist);\n",
    "title(str(c)+':'+str(totErr));\n",
    "print('Ideal results:')\n",
    "print(Y)\n",
    "print('Reality:')\n",
    "print(predY.T) # predicted Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 說明"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 測試結果大概到 360 多次就已經到達訓練的極限，無法再增加準確度，故增加訓練次數對於準確度的提升沒有影響。\n",
    "2. 嘗試調整 eta=0.1 (learning rate)，雖然有改變訓練的結果，但是預測的結果卻變得不準確。（因為eta變大，**delta learning** 變快，大 'deltaW=eta*outer(Y[p].T-y,X[p])'， backpropagation 的修正項變大）\n",
    "3. 本次因為資料的問題，所以無法透過 regression model 來接近所要的結果（接近Y），解釋原因如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 0],\n",
       "       [0, 1, 0, 0],\n",
       "       [1, 1, 0, 0],\n",
       "       [0, 0, 1, 0],\n",
       "       [0, 0, 0, 1],\n",
       "       [0, 0, 1, 1]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.819,  0.655,  0.108])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 結果Ｗ\n",
    "W"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'X' 是一個 6*4 的矩陣，而所要預測的 'Y' 是一個 6*2 的矩陣。\n",
    "可以利用線性代數的方法解釋，可以試 X 為 六個聯立方程式。我們看前三個連立方程式：\n",
    "\n",
    "'x = 1'\n",
    "\n",
    "'y = 1'\n",
    "\n",
    "'x + y = 1'\n",
    "\n",
    "'a = 1'\n",
    "\n",
    "'b = 1'\n",
    "\n",
    "'a + b = 1'\n",
    "\n",
    "不管由上面三式，或者下面三式，都無法找到解，所以這題無法使用一般的方法訓練出接近 'Y'(預期結果的答案)。\n",
    "加入修正項，來嘗試逼近結果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Write your codes with bias terms here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Write your discussions here, if any"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 PyTorch (3 points)\n",
    "Read <a href=\"http://noahsnail.com/2017/09/18/2017-9-18-PyTorch%E5%9F%BA%E6%9C%AC%E7%94%A8%E6%B3%95(%E4%B8%80)%E2%80%94%E2%80%94Numpy%EF%BC%8CTorch%E5%AF%B9%E6%AF%94/\">this tutorial</a> first and port the following Instar Learning from NumPy to PyTorch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.424  0.961  0.769] 0.71495969147\n",
      "[ 0.192  0.488  0.577] 0.454028223058\n",
      "[ 0.15   0.403  0.542] 0.406796473795\n",
      "[ 0.13   0.361  0.525] 0.383691868531\n",
      "[ 0.118  0.338  0.515] 0.37076457254\n",
      "[ 0.112  0.324  0.51 ] 0.363065804678\n",
      "[ 0.107  0.315  0.506] 0.358322057789\n",
      "[ 0.105  0.31   0.504] 0.355340080917\n",
      "[ 0.103  0.306  0.503] 0.353442536132\n",
      "[ 0.102  0.304  0.502] 0.352225797431\n"
     ]
    }
   ],
   "source": [
    "# Instar learning:\n",
    "x=array([0.1,0.3,0.5])\n",
    "W=random.rand(3)\n",
    "for i in range(10): # trials \n",
    "    y=dot(W,x)\n",
    "    print(W,y)\n",
    "    W+=y*(x-W) # Postsynaptically gated InStar "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Write your PyTorch codes here\n",
    "import torch as t\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.8192,  0.6548,  0.1083]) tensor(0.3325)\n",
      "tensor([ 0.5801,  0.5368,  0.2386]) tensor(0.6709)\n",
      "tensor([ 0.2580,  0.3779,  0.4140]) tensor(1.0170)\n",
      "tensor([ 0.0973,  0.2987,  0.5015]) tensor(1.3671)\n",
      "tensor([ 0.1010,  0.3005,  0.4995]) tensor(1.7171)\n",
      "tensor([ 0.0993,  0.2997,  0.5004]) tensor(2.0671)\n",
      "tensor([ 0.1008,  0.3004,  0.4996]) tensor(2.4171)\n",
      "tensor([ 0.0989,  0.2995,  0.5006]) tensor(2.7671)\n",
      "tensor([ 0.1019,  0.3009,  0.4990]) tensor(3.1171)\n"
     ]
    }
   ],
   "source": [
    "x=array([0.1,0.3,0.5])\n",
    "torch_data = t.FloatTensor(x)\n",
    "W=random.rand(3)\n",
    "torch_random = t.FloatTensor(W)\n",
    "dot_result = 0\n",
    "for i in range(1,10):\n",
    "    for i in range(0,3):\n",
    "        dot_result += torch_random[i]*torch_data[i]\n",
    "#     dot_result = torch_random.dot(torch_data)\n",
    "    print(torch_random, dot_result)\n",
    "    torch_random += dot_result * (torch_data - torch_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0960,  0.2980,  0.5022])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Self notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normal conversion between array and tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 2],\n",
       "       [3, 4, 5]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(6).reshape((2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numpy的array与torch的tensor的转换\n",
    "np_data = np.arange(6).reshape((2, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_data = t.from_numpy(np_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor2array = torch_data.numpy() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy data:  [[0 1 2]\n",
      " [3 4 5]]\n",
      "torch data:  tensor([[ 0,  1,  2],\n",
      "        [ 3,  4,  5]])\n",
      "tensor2array:  [[0 1 2]\n",
      " [3 4 5]]\n"
     ]
    }
   ],
   "source": [
    "print('numpy data: ', np_data)\n",
    "print('torch data: ', torch_data)\n",
    "print('tensor2array: ', tensor2array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversion to float tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-2., -1.,  0.,  1.,  2.])\n"
     ]
    }
   ],
   "source": [
    "data = [-2, -1, 0, 1, 2]\n",
    "float_data = t.FloatTensor(data)\n",
    "print(float_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 1 0 1 2]\n"
     ]
    }
   ],
   "source": [
    "print(np.abs(data))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversion to abs tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 2.,  1.,  0.,  1.,  2.])\n"
     ]
    }
   ],
   "source": [
    "print(t.abs(float_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversion to sin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.90929743 -0.84147098  0.          0.84147098  0.90929743]\n",
      "tensor([-0.9093, -0.8415,  0.0000,  0.8415,  0.9093])\n"
     ]
    }
   ],
   "source": [
    "print(np.sin(data))\n",
    "print(t.sin(float_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversion to mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "tensor(0.)\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(data))\n",
    "print(t.mean(float_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 7 10]\n",
      " [15 22]]\n"
     ]
    }
   ],
   "source": [
    "data = [[1, 2], [3, 4]]\n",
    "tensor = t.FloatTensor(data)\n",
    "print(np.matmul(data, data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  7.,  10.],\n",
      "        [ 15.,  22.]])\n",
      "tensor([[  7.,  10.],\n",
      "        [ 15.,  22.]])\n"
     ]
    }
   ],
   "source": [
    "# torch.mm不支持广播形式\n",
    "print(t.mm(tensor, tensor))\n",
    "# torch.matmul支持广播形式\n",
    "print(t.matmul(tensor, tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
